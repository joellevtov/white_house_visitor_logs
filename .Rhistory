wh_visitors_by_end_date <- wh_visitor_data |>
group_by(appt_end_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
#That looks better. Let's use appt end date because it seems to be the date col with the most data and fewest NAs.
wh_visitor_data |>
group_by(appt_end_date) |>
filter(total_people <100) |>
summarize(count=n()) |>
arrange(desc(count))
### Note - asked ChatGPT how to make the month column have labels and gave it my mutate code creating a new col with lubridate
#reading in approval ratings data from gallup
approval_ratings <- read_csv("data/biden_approval_gallup.csv", col_names = FALSE)
colnames(approval_ratings) <- c("poll_date", "rep_approval_pct", "ind_approval_pct", "dem_approval_pct")
approval_ratings <- approval_ratings |>
separate(poll_date, into = c("year", "month", sep = "-")) |>
select(year, month, rep_approval_pct, ind_approval_pct, dem_approval_pct)
approval_ratings <- approval_ratings |>
mutate(date = paste(year, month, sep = " "))
#making a df with top months for visitors
wh_visitor_by_month <- wh_visitors_by_end_date |>
mutate(date_time = ymd_hms(appt_end_date),
month = month.abb[month(appt_end_date)])
wh_visitor_by_month <- wh_visitor_by_month |>
group_by(month) |>
summarise(total_visits = sum(total_visits))
#last one not really helpful bc didn't sort by year. Now doing the same with year and month
wh_visitors_month_year <- wh_visitors_by_end_date |>
mutate(date_time = ymd_hms(appt_end_date),
month = month.abb[month(appt_end_date)],
year = year(date_time))
top_months_by_year <- wh_visitors_month_year |>
group_by(year, month) |>
summarise(total_visits = sum(total_visits))
#not sure if that was useful. I think I need to join these dataframes. Asked chatgpt for help with this because I needed to join on the date column and didn't have one with year and month in it for top_months_by_year. Asked it: I want to create a date column that looks like this: 2022 Jan, 2022 Feb, 2022 March. Currently I have a year column that looks like this: 2022, 2022, 2022, and a month column that looks like this: Jan, Feb, March. How can I create this new column using r and the tidyverse?
top_months_by_year <- top_months_by_year |>
mutate(date = as.Date(paste(year, month, "01"), format = "%Y %b %d"))
approval_ratings <- approval_ratings |>
mutate(date = as.Date(paste(year, month, "01"), format = "%Y %b %d"))
visits_by_month_ratings <- top_months_by_year |>
left_join(approval_ratings, by = "date") |>
rename(year = year.x, month = month.x) |>
select(-year.y, -month.y) |>
na.omit(visits_by_month_ratings)
#note - chatgpt wrote this code for me, I wanted to put these on the same graph but couldn't figure out the scale part
library(ggplot2)
ggplot(visits_by_month_ratings, aes(x = date)) +
# Bar chart for total_visits
geom_bar(aes(y = total_visits), stat = "identity", fill = "darkgray") +
# Line graphs for approval_ratings
geom_line(aes(y = dem_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "blue") +
geom_line(aes(y = ind_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "darkgreen") +
geom_line(aes(y = rep_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "red") +
# Y-axis scale for total_visits
scale_y_continuous(name = "Total Visits", breaks = seq(0, 70000, by = 10000)) +
# Secondary Y-axis scale for approval_rating
scale_y_continuous(
name = "Total Visits",
sec.axis = sec_axis(~ . * max(visits_by_month_ratings$dem_approval_pct) / max(visits_by_month_ratings$total_visits), name = "Dem Approval Rating")
) +
theme_gray()
#note - not sure if this is actually a valuable graph. Should we just throw out 2021 data because it's so sparse compared to 2022/23? Does this highlight fluctuations in visits or just a lack of data for earlier months? Also it wouldn't graph Dec 2022 which was the second highest month because of NA values in the approval ratings. @DEREK is there a way around this?
# July 2 calculation
wh_visitor_data |>
filter(str_detect(appt_end_date, "2023-07-02")) |>
group_by(appt_end_date) |>
summarize(sum= sum(total_people))
# so 1994 people visited the white house on that date. let's check what the average amount of people on monday is.
wh_visitor_data |>
mutate(day_of_week = wday(appt_end_date)) |>
filter(day_of_week == 1) |>
group_by(appt_end_date) |>
summarize(total_people = sum(total_people)) |>
filter(!is.na(total_people)) |>
summary(round(total_people))
wh_visitors_per_day <- wh_visitor_data |>
mutate(date = date(appt_end_date)) |>
group_by(date) |>
summarize(total_people = sum(total_people)) |>
filter(!is.na(total_people))
#answer - 33801 is the average number of visitors via the mean but that's thrown off by a couple days with an insanely high number of visitors. the median is more reasonable, 139.
# funny. let's make a scatterplot with a line of best fit to see what the distribution is. perhaps the number of visitors has increased as time as went on?
# without the function (thanks bard) ggplot was displaying like 2e19 which if i really think hard i can decipher but i am lazy so i made it display in a reasonable format
format_numbers <- function(x) format(x, big.mark = ",", trim = 0)
scatter_visitors_day <-
ggplot(data=wh_visitors_per_day) +
geom_point(aes(x=date, y=total_people))
scatter_visitors_day <- scatter_visitors_day + scale_y_continuous(labels = format_numbers)
# It looks like the answer is not really. The days with tens of thousands of people seem to be big outliers, something is screwy with the white house's data
wh_visitors_per_day |>
arrange(desc(total_people))
# on 12/01/2022, for example, several groups of 5,619 people allegedly toured the white house to visit kevin ballen. i looked him up and it looks like he's a really annoying (at least from his looks) literally-just-graduated Harvard alum who completed a bachelor's.
# edit: the more i read about him the more i am convinced he is an annoying person. from a crimson puff piece:
# Kevin Ballen didn’t plan on taking two gap years. But he did intend to live a life less constrained by society’s expectations. [...] But a single moment made him rethink his altruistic efforts. It happened outside a local supermarket at a fundraiser for a day care that served homeless children. At the last minute, student leaders were unable to attend and Ballen was put in charge. “It was a realization of agency and what was possible for a young person like me,” he said. “I was able to lead a team, to make tangible change, to use my creativity.”
# sounds like someone owed this kid's parent a favor. cHrist.
# edit #2: it gets worse the more i look. this kid's thesis topic - i shit you not - that got featured on the harvard tiktok was literally "young people don't love taxes as much as he does."
# i decided to take a look at what the actual hell is happening on one of the days with a gigantic number of people. first, Dec. 1 2022. Macron visited the White House on that day.
wh_visitor_data |>
filter(str_detect(appt_end_date, "2022-12-01")) |>
select(total_people, namelast, namefirst, visitee_namelast, visitee_namefirst) |>
arrange(desc(total_people))
# What's really strange is that 5619 people are visiting Ballen over and over. And they're not vising Joe Biden. I think he's either running a covert drug operation, an illicit prostitution ring (maybe Pizzagate wasn't that far off after all??), or this is a weird data keeping error. Let's see if it continues with the other days.
wh_visitor_data |>
filter(str_detect(appt_end_date, "2022-09-13")) |>
select(total_people, namelast, namefirst, visitee_namelast, visitee_namefirst) |>
arrange(desc(total_people))
# So on this day, which is the day with the second most people visiting the white house, we see the weird repetition of the number of people visiting again, 4478 this time visiting Biden. Let's look at July 4, 2022. A large amount of people would make sense on that day.
wh_visitor_data |>
filter(str_detect(appt_end_date, "2023-07-04")) |>
select(namefirst, namelast,  visitee_namefirst, visitee_namelast, total_people) |>
arrange(desc(total_people))
# So this time the magic number is 1182. They're all (allegedly) visiting Bonnie Casillas, the associate director for White House operations. Let's see if there are any rows with a reasonable amount of people visiting.
wh_visitor_data |>
filter(str_detect(appt_end_date, "2023-07-04")) |>
filter(total_people != 1182) |>
select(namefirst, namelast,  visitee_namefirst, visitee_namelast, total_people) |>
arrange(desc(total_people))
# Uhh. Now we have 788 people visiting Biden over and over again. Also strange. Let's see what happens when we filter out both 1182 and 788
wh_visitor_data |>
filter(str_detect(appt_end_date, "2023-07-04")) |>
filter(total_people != 1182 & total_people != 788) |>
select(namefirst, namelast,  visitee_namefirst, visitee_namelast, total_people) |>
arrange(desc(total_people))
# Now 752 is the number du jour. Jesus christ.
wh_visitor_data |>
filter(str_detect(appt_end_date, "2023-07-04")) |>
filter(total_people != 1182 & total_people != 788 & total_people !=752) |>
select(namefirst, namelast,  visitee_namefirst, visitee_namelast, total_people) |>
arrange(desc(total_people))
# This is really weird.
wh_visitor_data |>
filter(str_detect(appt_end_date, "2023-07-04")) |>
unique(total_people) |>
select(namefirst, namelast,  visitee_namefirst, visitee_namelast, total_people) |>
arrange(desc(total_people))
wh_visitors_by_end_date
install.packages(corrr)
library(tidyverse)
library(janitor)
library(lubridate)
library(corrr)
install.packages("corrr")
library(tidyverse)
library(janitor)
library(lubridate)
library(corrr)
#note - chatgpt wrote this code for me, I wanted to put these on the same graph but couldn't figure out the scale part
library(ggplot2)
ggplot(visits_by_month_ratings, aes(x = date)) +
# Bar chart for total_visits
geom_bar(aes(y = total_visits), stat = "identity", fill = "darkgray") +
# Line graphs for approval_ratings
geom_line(aes(y = dem_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "blue") +
geom_line(aes(y = ind_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "darkgreen") +
geom_line(aes(y = rep_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "red") +
# Y-axis scale for total_visits
scale_y_continuous(name = "Total Visits", breaks = seq(0, 70000, by = 10000)) +
# Secondary Y-axis scale for approval_rating
scale_y_continuous(
name = "Total Visits",
sec.axis = sec_axis(~ . * max(visits_by_month_ratings$dem_approval_pct) / max(visits_by_month_ratings$total_visits), name = "Dem Approval Rating")
) +
theme_gray()
#note - not sure if this is actually a valuable graph. Should we just throw out 2021 data because it's so sparse compared to 2022/23? Does this highlight fluctuations in visits or just a lack of data for earlier months?
library(tidyverse)
library(janitor)
library(lubridate)
library(corrr)
wh_visitor_data <- read_csv("data/combined.csv") |> clean_names() |>
mutate(toa = mdy_hm(toa)) |>
mutate(tod = mdy_hm(tod)) |>
mutate(appt_made_date = mdy_hm(appt_made_date))  |>
mutate(appt_start_date = mdy(appt_start_date))  |>
mutate(appt_end_date = mdy_hm(appt_end_date))  |>
mutate(lastentrydate = mdy_hm(lastentrydate))  |>
mutate(releasedate = mdy(releasedate))
glimpse(wh_visitor_data)
###note - we were having problems with this so I asked chatgpt: how do I make a new column with just the date from a column that includes date and time using lubridate and the tidyverse? it told me to do mutate(toa_date = ymd_hms(toa) %>% date())
wh_visitor_data <- wh_visitor_data |>
mutate(toa_date = ymd_hms(toa) |> date())
wh_visitor_data |>
group_by(toa_date) |>
summarize(count=n()) |>
arrange(desc(count))
# note - since there are so many NA dates here, I think we should group by appt date.
wh_visitor_data |>
group_by(appt_start_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
### just kidding, there are a ton of NA dates still. maybe appt end date?
wh_visitor_data |>
group_by(appt_end_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
### this seems better
### Note - asked ChatGPT how to make the month column have labels and gave it my mutate code creating a new col with lubridate
#reading in approval ratings data from galup
approval_ratings <- read_csv("data/biden_approval_gallup.csv", col_names = FALSE)
colnames(approval_ratings) <- c("poll_date", "rep_approval_pct", "ind_approval_pct", "dem_approval_pct")
approval_ratings <- approval_ratings |>
separate(poll_date, into = c("year", "month", sep = "-")) |>
select(year, month, rep_approval_pct, ind_approval_pct, dem_approval_pct)
approval_ratings <- approval_ratings |>
mutate(date = paste(year, month, sep = " "))
#making a df with top months for visitors
wh_visitor_by_month <- wh_visitors_by_end_date |>
mutate(date_time = ymd_hms(appt_end_date),
month = month.abb[month(appt_end_date)])
wh_visitors_by_end_date <- wh_visitor_data |>
group_by(appt_end_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
View(wh_visitors_by_end_date)
### Note - asked ChatGPT how to make the month column have labels and gave it my mutate code creating a new col with lubridate
#reading in approval ratings data from galup
approval_ratings <- read_csv("data/biden_approval_gallup.csv", col_names = FALSE)
colnames(approval_ratings) <- c("poll_date", "rep_approval_pct", "ind_approval_pct", "dem_approval_pct")
approval_ratings <- approval_ratings |>
separate(poll_date, into = c("year", "month", sep = "-")) |>
select(year, month, rep_approval_pct, ind_approval_pct, dem_approval_pct)
approval_ratings <- approval_ratings |>
mutate(date = paste(year, month, sep = " "))
#making a df with top months for visitors
wh_visitor_by_month <- wh_visitors_by_end_date |>
mutate(date_time = ymd_hms(appt_end_date),
month = month.abb[month(appt_end_date)])
wh_visitor_by_month <- wh_visitor_by_month |>
group_by(month) |>
summarise(total_visits = sum(total_visits))
#last one not really helpful bc didn't sort by year. Now doing the same with year and month
wh_visitors_month_year <- wh_visitors_by_end_date |>
mutate(date_time = ymd_hms(appt_end_date),
month = month.abb[month(appt_end_date)],
year = year(date_time))
top_months_by_year <- wh_visitors_month_year |>
group_by(year, month) |>
summarise(total_visits = sum(total_visits))
#not sure if that was useful. I think I need to join these dataframes. Asked chatgpt for help with this because I needed to join on the date column and didn't have one with year and month in it for top_months_by_year. Asked it: I want to create a date column that looks like this: 2022 Jan, 2022 Feb, 2022 March. Currently I have a year column that looks like this: 2022, 2022, 2022, and a month column that looks like this: Jan, Feb, March. How can I create this new column using r and the tidyverse?
top_months_by_year <- top_months_by_year |>
mutate(date = as.Date(paste(year, month, "01"), format = "%Y %b %d"))
approval_ratings <- approval_ratings |>
mutate(date = as.Date(paste(year, month, "01"), format = "%Y %b %d"))
visits_by_month_ratings <- top_months_by_year |>
left_join(approval_ratings, by = "date") |>
rename(year = year.x, month = month.x) |>
select(-year.y, -month.y) |>
na.omit(visits_by_month_ratings)
View(visits_by_month_ratings)
#let's take out 2021 data
visits_by_month_ratings |> filter (date > "2021-12-31")
#state_data |>
# select(-state, -vote_2020) |>
#correlate()
library(tidyverse)
library(janitor)
library(lubridate)
library(corrr)
wh_visitor_data <- read_csv("data/combined.csv") |> clean_names() |>
mutate(toa = mdy_hm(toa)) |>
mutate(tod = mdy_hm(tod)) |>
mutate(appt_made_date = mdy_hm(appt_made_date))  |>
mutate(appt_start_date = mdy(appt_start_date))  |>
mutate(appt_end_date = mdy_hm(appt_end_date))  |>
mutate(lastentrydate = mdy_hm(lastentrydate))  |>
mutate(releasedate = mdy(releasedate))
glimpse(wh_visitor_data)
###note - we were having problems with this so I asked chatgpt: how do I make a new column with just the date from a column that includes date and time using lubridate and the tidyverse? it told me to do mutate(toa_date = ymd_hms(toa) %>% date())
wh_visitor_data <- wh_visitor_data |>
mutate(toa_date = ymd_hms(toa) |> date())
wh_visitor_data |>
group_by(toa_date) |>
summarize(count=n()) |>
arrange(desc(count))
# note - since there are so many NA dates here, I think we should group by appt date.
wh_visitor_data |>
group_by(appt_start_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
### just kidding, there are a ton of NA dates still. maybe appt end date?
wh_visitors_by_end_date <- wh_visitor_data |>
group_by(appt_end_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
### this seems better
### Note - asked ChatGPT how to make the month column have labels and gave it my mutate code creating a new col with lubridate
#reading in approval ratings data from galup
approval_ratings <- read_csv("data/biden_approval_gallup.csv", col_names = FALSE)
colnames(approval_ratings) <- c("poll_date", "rep_approval_pct", "ind_approval_pct", "dem_approval_pct")
approval_ratings <- approval_ratings |>
separate(poll_date, into = c("year", "month", sep = "-")) |>
select(year, month, rep_approval_pct, ind_approval_pct, dem_approval_pct)
approval_ratings <- approval_ratings |>
mutate(date = paste(year, month, sep = " "))
#making a df with top months for visitors
wh_visitor_by_month <- wh_visitors_by_end_date |>
mutate(date_time = ymd_hms(appt_end_date),
month = month.abb[month(appt_end_date)])
wh_visitor_by_month <- wh_visitor_by_month |>
group_by(month) |>
summarise(total_visits = sum(total_visits))
#last one not really helpful bc didn't sort by year. Now doing the same with year and month
wh_visitors_month_year <- wh_visitors_by_end_date |>
mutate(date_time = ymd_hms(appt_end_date),
month = month.abb[month(appt_end_date)],
year = year(date_time))
top_months_by_year <- wh_visitors_month_year |>
group_by(year, month) |>
summarise(total_visits = sum(total_visits))
#lets make some different dfs so we can graph by year?
top_months_2023 <- top_months_by_year |>
filter(year == 2023) |>
group_by(month) |>
summarise(total_visits)
top_months_22 <- top_months_by_year |>
filter(year == 2022) |>
group_by(month) |>
summarise(total_visits)
top_months_21 <- top_months_by_year |>
filter(year == 2021) |>
group_by(month) |>
summarise(total_visits)
#not sure if that was useful. I think I need to join these dataframes. Asked chatgpt for help with this because I needed to join on the date column and didn't have one with year and month in it for top_months_by_year. Asked it: I want to create a date column that looks like this: 2022 Jan, 2022 Feb, 2022 March. Currently I have a year column that looks like this: 2022, 2022, 2022, and a month column that looks like this: Jan, Feb, March. How can I create this new column using r and the tidyverse?
top_months_by_year <- top_months_by_year |>
mutate(date = as.Date(paste(year, month, "01"), format = "%Y %b %d"))
approval_ratings <- approval_ratings |>
mutate(date = as.Date(paste(year, month, "01"), format = "%Y %b %d"))
visits_by_month_ratings <- top_months_by_year |>
left_join(approval_ratings, by = "date") |>
rename(year = year.x, month = month.x) |>
select(-year.y, -month.y) |>
na.omit(visits_by_month_ratings)
#now lets make some bar charts of visits per month each year
months_23 <- ggplot(top_months_2023, aes(x = month)) +
geom_bar(aes(y = total_visits), stat = "identity", fill = "blue", alpha = 0.5) +
labs(y = "total_visits", x = "month")
months_22 <- ggplot(top_months_22, aes(x = month)) +
geom_bar(aes(y = total_visits), stat = "identity", fill = "blue", alpha = 0.5) +
labs(y = "total_visits", x = "month")
months_21 <- ggplot(top_months_21, aes(x = month)) +
geom_bar(aes(y = total_visits), stat = "identity", fill = "blue", alpha = 0.5) +
labs(y = "total_visits", x = "month")
#note - chatgpt wrote this code for me, I wanted to put these on the same graph but couldn't figure out the scale part
library(ggplot2)
ggplot(visits_by_month_ratings, aes(x = date)) +
# Bar chart for total_visits
geom_bar(aes(y = total_visits), stat = "identity", fill = "darkgray") +
# Line graphs for approval_ratings
geom_line(aes(y = dem_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "blue") +
geom_line(aes(y = ind_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "darkgreen") +
geom_line(aes(y = rep_approval_pct * max(total_visits) / max(dem_approval_pct)), color = "red") +
# Y-axis scale for total_visits
scale_y_continuous(name = "Total Visits", breaks = seq(0, 70000, by = 10000)) +
# Secondary Y-axis scale for approval_rating
scale_y_continuous(
name = "Total Visits",
sec.axis = sec_axis(~ . * max(visits_by_month_ratings$dem_approval_pct) / max(visits_by_month_ratings$total_visits), name = "Dem Approval Rating")
) +
theme_gray()
#note - not sure if this is actually a valuable graph. Should we just throw out 2021 data because it's so sparse compared to 2022/23? Does this highlight fluctuations in visits or just a lack of data for earlier months?
#let's take out 2021 data
visits_by_month_ratings |> filter (date > "2021-12-31")
#now let's take out the non-numeric data
month_ratings_dbl <- visits_by_month_ratings |>
select(-year, -month, -date)
#now let's run the correlation test
visits_by_month_ratings |>
# select(-state, -vote_2020) |>
#correlate()
View(month_ratings_dbl)
#let's take out 2021 data
month_ratings_post_covid <- visits_by_month_ratings |> filter (date > "2021-12-31")
#now let's take out the non-numeric data
#month_ratings_dbl <- visits_by_month_ratings |>
#select(-year, -month, -date)
#now let's run the correlation test
month_ratings_post_covid |>
select(-year, -month, -date) |>
correlate()
### need to clean data in open refine :)
open_refine_cleaned_visitors <- read_csv("data/open_refined_wh_data_combined.csv")
setwd("~/data_journalism/data_journalism_fall_2023/major_assignments/group_project_2/white_house_visitor_logs")
### need to clean data in open refine :)
open_refine_cleaned_visitors <- read_csv("data/open_refined_wh_data_combined.csv")
### need to clean data in open refine :)
open_refine_cleaned_visitors <- read_csv("data/cleaned_OPENREFINE.csv")
open_refine_cleaned_visitors |> group_by(VISITEE_NAMELAST_CLEAN, VISITEE_NAMEFIRST_CLEAN) |>
summarise(visits = n()) |>
arrange(desc(visits))
View(wh_visitor_by_month)
View(wh_visitors_month_year)
View(wh_visitor_data)
library(tidyverse)
library(janitor)
library(lubridate)
library(corrr)
wh_visitor_data <- read_csv("data/cleaned_OPENREFINE.csv")
View(wh_visitor_data)
wh_visitor_data <- read_csv("data/cleaned_OPENREFINE.csv") |> clean_names() |>
mutate(toa = mdy_hm(toa)) |>
mutate(tod = mdy_hm(tod)) |>
mutate(appt_made_date = mdy_hm(appt_made_date))  |>
mutate(appt_start_date = mdy(appt_start_date))  |>
mutate(appt_end_date = mdy_hm(appt_end_date))  |>
mutate(lastentrydate = mdy_hm(lastentrydate))  |>
mutate(releasedate = mdy(releasedate))
wh_visitor_data <- read_csv("data/cleaned_OPENREFINE.csv")
library(tidyverse)
library(janitor)
library(lubridate)
library(ggplot2) #make sure you have ggplot 2 installed, not ggplot
options(scipen=999)
###asked chatgpt how to turn a character column into a date time column, gave it some examples from our code and int told me to do this:
wh_visitor_data <- read_csv("data/cleaned_OPENREFINE.csv") |>
clean_names()
wh_visitor_data <- wh_visitor_data |>
mutate(appt_end_date = mdy_hm(appt_end_date))
glimpse(wh_visitor_data)
####mutate(toa_time = ymd_hms(toa) |> time()) we need to figure out how to separate out time from these two columns as well
wh_visitor_data |>
group_by(toa) |>
summarize(count=n()) |>
arrange(desc(count))
# note - since there are so many NA dates here, I think we should group by appt date.
wh_visitors_by_date <- wh_visitor_data |>
group_by(appt_start_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
### just kidding, there are a ton of NA dates still. maybe appt end date?
wh_visitors_by_end_date <- wh_visitor_data |>
group_by(appt_end_date) |>
summarize(total_visits = n()) |>
arrange(desc(total_visits))
### this seems better
###derek asked if the NA dates were specific to certain offices. how do we figure that out?
wh_visitor_data |> filter(if_any(-toa_date, is.na)) |>
group_by(meeting_loc) |>
summarise(count = n())
wh_visitor_data <- wh_visitor_data |>
mutate(
visitee_namelast_clean = case_when(
tolower(visitee_namefirst_clean) == "potus" ~ "Biden",
tolower(visitee_namefirst_clean) == "flotus" ~ "Biden",
tolower(visitee_namefirst_clean) == "vpotus" ~ "Harris",
TRUE ~ visitee_namelast_clean
),
visitee_namefirst_clean = case_when(
tolower(visitee_namefirst_clean) == "potus" ~ "Joe",
tolower(visitee_namefirst_clean) == "flotus" ~ "Jill",
tolower(visitee_namefirst_clean) == "vpotus" ~ "Kamala",
TRUE ~ visitee_namefirst_clean
)
)
wh_visitor_data <- wh_visitor_data |>
mutate(
visitee_namelast_clean = case_when(
tolower(visitee_namefirst_clean) == "potus" ~ "Biden",
tolower(visitee_namefirst_clean) == "flotus" ~ "Biden",
tolower(visitee_namefirst_clean) == "vpotus" ~ "Harris",
TRUE ~ visitee_namelast_clean
),
visitee_namefirst_clean = case_when(
tolower(visitee_namefirst_clean) == "potus" ~ "Joe",
tolower(visitee_namefirst_clean) == "flotus" ~ "Jill",
tolower(visitee_namefirst_clean) == "vpotus" ~ "Kamala",
TRUE ~ visitee_namefirst_clean
)
) |>
mutate(
visitee_namelast_clean = toTitleCase(visitee_namelast_clean),
visitee_namefirst_clean = toTitleCase(visitee_namefirst_clean)
)
library(tools)
wh_visitor_data <- wh_visitor_data |>
mutate(
visitee_namelast_clean = case_when(
tolower(visitee_namefirst_clean) == "potus" ~ "Biden",
tolower(visitee_namefirst_clean) == "flotus" ~ "Biden",
tolower(visitee_namefirst_clean) == "vpotus" ~ "Harris",
TRUE ~ visitee_namelast_clean
),
visitee_namefirst_clean = case_when(
tolower(visitee_namefirst_clean) == "potus" ~ "Joe",
tolower(visitee_namefirst_clean) == "flotus" ~ "Jill",
tolower(visitee_namefirst_clean) == "vpotus" ~ "Kamala",
TRUE ~ visitee_namefirst_clean
)
) |>
mutate(
visitee_namelast_clean = toTitleCase(visitee_namelast_clean),
visitee_namefirst_clean = toTitleCase(visitee_namefirst_clean)
)
#now let's run that data again
wh_visitor_data |>
group_by(visitee_namefirst_clean, visitee_namelast_clean) |>
summarise(visits = n()) |>
arrange(desc(visits))
library(tools)
wh_visitor_data <- wh_visitor_data |>
mutate(
visitee_namelast_clean = case_when(
toTitleCase(visitee_namefirst_clean) == "Potus" ~ "Biden",
toTitleCase(visitee_namefirst_clean) == "Flotus" ~ "Biden",
toTitleCase(visitee_namefirst_clean) == "Vpotus" ~ "Harris",
TRUE ~ visitee_namelast_clean
),
visitee_namefirst_clean = case_when(
toTitleCase(visitee_namefirst_clean) == "Potus" ~ "Joe",
toTitleCase(visitee_namefirst_clean) == "Flotus" ~ "Jill",
toTitleCase(visitee_namefirst_clean) == "Vpotus" ~ "Kamala",
TRUE ~ visitee_namefirst_clean
)
)
