summarise(count = n())
View(md_zipcodes)
View(moco_2022_zipcalls)
moco_2022_zipcalls |>
left_join(md_over_18, join_by(NAME==zip))
moco_2022_zipcalls |>
left_join(md_over_18, join_by(zip==NAME))
moco_2022_zipcalls$zip <- as.character(moco_2022_zipcalls$zip)
moco_2022_zipcalls |>
left_join(md_over_18, join_by(zip==NAME))
View(moco_2022_zipcalls)
moco_2022_zipcalls$zip <- as.character(moco_2022_zipcalls$zip)
joined_moco_zip_pop <- moco_2022_zipcalls |>
left_join(md_over_18, join_by(zip==NAME))
View(joined_moco_zip_pop)
View(md_zipcodes)
md_over_18 <- get_acs(geography="zcta", variables = "B09021_001", state='MD', year=2019)
View(md_over_18)
moco_2022_zipcalls$zip <- as.character(moco_2022_zipcalls$zip)
joined_moco_zip_pop <- moco_2022_zipcalls |>
left_join(md_over_18, join_by(zip==NAME))
View(joined_moco_zip_pop)
View(moco_2022_zipcalls)
View(md_over_18)
moco_2022_overdoses <- read_csv("data/montgomery_2022_overdoses.csv")
moco_2022_zipcalls <- moco_2022_overdoses |>
group_by(zip) |>
summarise(count = n())
md_over_18 <- get_acs(geography="zcta", variables = "B09021_001", year=2019)
moco_2022_zipcalls$zip <- as.character(moco_2022_zipcalls$zip)
joined_moco_zip_pop <- md_over_18 |>
inner_join(moco_2022_zipcalls, join_by(NAME==zip))
View(joined_moco_zip_pop)
moco_2022_overdoses <- read_csv("data/montgomery_2022_overdoses.csv")
moco_2022_zipcalls <- moco_2022_overdoses |>
group_by(zip) |>
summarise(count = n())
md_over_18 <- get_acs(geography="zcta", variables = "B09021_001", year=2019)
moco_2022_zipcalls$zip <- as.character(moco_2022_zipcalls$zip)
joined_moco_zip_pop <- md_over_18 |>
inner_join(moco_2022_zipcalls, join_by(GEOID==zip))
View(joined_moco_zip_pop)
view(joined_moco_zip_pop)
View(moco_2022_zipcalls)
moco_2022_zipcalls <- moco_2022_overdoses |>
group_by(zip) |>
summarise(count = n())
md_over_18 <- get_acs(geography="zcta", variables = "B09021_001", year=2019)
joined_moco_zip_pop <- md_over_18 |>
inner_join(moco_2022_zipcalls, join_by(GEOID==zip))
moco_2022_zipcalls$zip <- as.character(moco_2022_zipcalls$zip)
joined_moco_zip_pop <- md_over_18 |>
inner_join(moco_2022_zipcalls, join_by(GEOID==zip))
View(joined_moco_zip_pop)
colnames(joined_moco_zip_pop$count) <- c("num_of_calls")
joined_moco_zip_pop |>
colnames("count") <- c("num_of_calls")
joined_moco_zip_pop |>
colnames(count) <- c(num_of_calls)
colnames(joined_moco_zip_pop) [5] <- c("num_of_calls")
joined_moco_zip_pop <- colnames(joined_moco_zip_pop) [5] <- c("num_of_calls")
joined_moco_zip_pop <- md_over_18 |>
inner_join(moco_2022_zipcalls, join_by(GEOID==zip))
joined_moco_zip_pop <- joined_moco_zip_pop|>
rename(num_calls = count)
View(joined_moco_zip_pop)
joined_moco_zip_pop <- joined_moco_zip_pop|>
rename(num_calls = count, num_people = estimate)
joined_moco_zip_pop <- joined_moco_zip_pop|>
rename(num_calls = count & num_people = estimate)
joined_moco_zip_pop <- joined_moco_zip_pop|>
rename(num_calls = count) |>
rename(num_people = estimate)
joined_moco_zip_pop <- md_over_18 |>
inner_join(moco_2022_zipcalls, join_by(GEOID==zip))
joined_moco_zip_pop <- joined_moco_zip_pop|>
rename(num_calls = count) |>
rename(num_people = estimate)
rename(zip_code = GEOID)
joined_moco_zip_pop <- joined_moco_zip_pop|>
rename(zip_code = GEOID)
joined_moco_zip_pop |>
mutate(pct_calls = (num_calls/num_people)*1000)
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(pct_calls = (num_calls/num_people)*1000)
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(pct_calls = (num_calls/num_people))
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(pct_calls = (num_calls/num_people)*1000*100)
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(pct_calls = (num_calls/num_people)*1000)
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(calls_per_thousand = (num_calls/num_people)*1000)
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(calls_per_thousand = (num_calls/num_people)*1000) |>
arrange(desc(calls_per_thousand))
View(acs2021_5yr)
moco_race <- get_acs(geography="zcta", variables = "B09021_00", 1:10, year=2019)
variables <- paste0("B0200", 1:10)
moco_race <- get_acs(geography="zcta", variables = "B09021_00", 1:10)
moco_race <- get_acs(
geography = "zcta",
variables = paste0("B09021_", 1:10),
year = 2019
)
moco_race <- get_acs(
geography = "zcta",
variables = paste0("B09021_00", 1:10),
year = 2019
)
# Load the tidycensus package
library(tidycensus)
# Use get_acs to retrieve the variables with paste0
moco_race <- get_acs(
geography = "zcta",
variables = paste0("B09021_", 1:10),
year = 2019
)
moco_race <- get_acs(
geography = "zcta",
variables = paste0("B09021_", 1:10)
)
moco_race <- get_acs(
geography = "zcta",
variables = paste0("B09021_00", 1:10)
)
vars <- paste0("B01001_0", c(20:25, 44:49))
moco_race <- get_acs(
geography = "zcta",
variables = paste0("B09021_", c(1:10)),
year = 2019
)
vars <- paste0("B01001_0", 1:10)
# Use get_acs to retrieve the variables with paste0
moco_race <- get_acs(
geography = "zcta",
variables = paste0("B02001_", c(1:10)),
year = 2019
)
moco_race <- get_acs(
geography = "zcta",
variables = vars = vars),
moco_race <- get_acs(
geography = "zcta",
variables = (vars = vars)),
moco_race <- get_acs(
geography = "zcta",
variables = vars,
year = 2019
)
vars
salt_lake <- get_acs(
geography = "tract",
variables = vars,
state = "Utah",
county = "Salt Lake",
year = 2020
)
vars <- paste0("B01001_0", c(20:25, 44:49))
salt_lake <- get_acs(
geography = "tract",
variables = vars,
state = "Utah",
county = "Salt Lake",
year = 2020
)
vars <- paste0("B01001_0", 1:10)
vars <- paste0("B01001_0", 1:10)
vars
vars <- paste0("B01001_00", 1:9, "B01001_010")
moco_race <- get_acs(
geography = "zcta",
variables = vars
)
vars <- paste0("B01001_00", 1:10)
vars
vars <- paste0("B01001_0", 1:10)
vars
vars <- paste0("B01001_00", 1:10)
vars
salt_lake <- get_acs(
geography = "tract",
variables = vars,
state = "Utah",
county = "Salt Lake",
year = 2020
)
moco_race <- get_acs(
geography = "zcta",
variables = c("B01001_001", "B01001_002")
)
moco_race <- get_acs(
geography = "state",
variables = c("B01001_001", "B01001_002")
)
moco_race <- get_acs(
geography = "zip code tabulation area",
variables = c("B01001_001", "B01001_002")
)
View(moco_race)
moco_race <- get_acs(
geography = "zip code tabulation area",
variable = c("B01001_001", "B01001_002")
)
moco_race <- get_acs(
geography = "zip code tabulation area",
variables = c("B01001_001", "B01001_002"),
year=2021
)
vars <- paste0("B01001_00", 1:10)
moco_race <- get_acs(
geography = "zip code tabulation area",
variables = vars,
year=2021
)
joined_moco_zip_pop |>
mutate(min_people = num_people-moe) |>
mutate(max_people = num_people+moe)
joined_moco_zip_pop |>
mutate(min_people = num_people-moe) |>
mutate(max_people = num_people+moe) |>
mutate(min_per_thousand = min_people/num_calls) |>
mutate(max_per_thousand = max_people/num_calls)
joined_moco_zip_pop |>
arrange(desc(min_per_thosand))
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(min_people = num_people-moe) |>
mutate(max_people = num_people+moe) |>
mutate(min_per_thousand = min_people/num_calls) |>
mutate(max_per_thousand = max_people/num_calls)
joined_moco_zip_pop |>
arrange(desc(min_per_thosand))
joined_moco_zip_pop <- joined_moco_zip_pop |>
mutate(min_people = num_people-moe) |>
mutate(max_people = num_people+moe) |>
mutate(min_per_thousand = min_people/num_calls) |>
mutate(max_per_thousand = max_people/num_calls)
joined_moco_zip_pop |>
arrange(desc(min_per_thousand))
joined_moco_zip_pop |>
arrange(desc(max_per_thousand))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
baltco_911_calls <- read_csv("data/baltco_911_calls.csv")
baltco_911_calls_by_month <- baltco_911_calls |>
mutate(month = month(date, label=TRUE)) |>
group_by(month) |>
summarize(total_calls = n()) |>
arrange(desc(total_calls))
baltco_911_calls_by_month
baltco_911_calls_by_month <- baltco_911_calls |>
mutate(month = month(date, label=FALSE)) |>
group_by(month) |>
summarize(total_calls = n()) |>
arrange(desc(total_calls))
baltco_911_calls_by_month
baltco_911_calls_by_month <- baltco_911_calls |>
mutate(month = month(date, label=TRUE)) |>
group_by(month) |>
summarize(total_calls = n()) |>
arrange(desc(total_calls))
baltco_911_calls_by_month
knitr::opts_chunk$set(echo = TRUE)
baltco_911_calls_by_month |>
ggplot()
baltco_911_calls_by_month |>
ggplot() +
geom_bar(aes(x=month, weight=total_calls))
baltco_911_calls_by_month |>
ggplot() +
geom_bar(aes(x=reorder(month,total_calls), weight=total_calls))
baltco_911_calls_by_month |>
ggplot() +
geom_bar(aes(x=reorder(month,total_calls), weight=total_calls)) +
coord_flip()
baltco_911_calls_by_month |>
ggplot() +
geom_bar(aes(x=reorder(month,total_calls), weight=total_calls)) +
coord_flip() +
theme_minimal()
install.packages('ggthemes')
library(ggthemes)
baltco_911_calls_by_month |>
ggplot() +
geom_bar(aes(x=reorder(month,total_calls), weight=total_calls)) +
coord_flip() +
theme_economist()
baltco_911_calls_by_month |>
ggplot() +
geom_bar(aes(x=reorder(month,total_calls), weight=total_calls)) +
coord_flip() +
theme_economist() +
labs(
title="More 911 Overdose Calls in Warmer Months",
x = "month",
y = "total calls",
caption = "source: Baltimore County"
)
baltco_911_calls_by_date <- baltco_911_calls |>
group_by(date) |>
summarise(
total_calls=n()
)
baltco_911_calls_by_date
baltco_911_calls_by_date |>
ggplot() +
geom_line(aes(x=date, y=total_calls))
baltco_911_calls_by_date |>
ggplot() +
geom_line(aes(x=date, y=total_calls)) +
scale_x_date(date_breaks = "1 week", date_labels = "%b %d")
baltco_911_calls_by_date |>
ggplot() +
geom_line(aes(x=date, y=total_calls)) +
scale_x_date(date_breaks = "1 week", date_labels = "%b %d") +
theme(
axis.text.x = element_text(angle = 45,  hjust=1)
)
baltco_911_calls_by_month <- baltco_911_calls |> #saving it out to a new dataframe
mutate(month = month(date, label=TRUE)) |> #making the month column usable, label=TRUE means it'll show "August" instead of "8"
group_by(month) |> #preparing
summarize(total_calls = n()) |>
arrange(desc(total_calls))
baltco_911_calls_by_month
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics("images/geolayers.jpg")
library(tidyverse)
library(sf)
library(janitor)
# library(maptools)
md_zips <- st_read("data/md_zips/BNDY_ZIPCodes11Digit_MDP.shp")
glimpse(md_zips)
View(md_zips)
md_zips |>
ggplot() +
geom_sf() +
theme_minimal()
# install.packages('tigris')
library(tigris)
counties <- counties()
glimpse(counties)
md_counties <- counties |>
filter(STATEFP == "24")
md_counties |>
ggplot() +
geom_sf() +
theme_minimal()
ggplot() +
geom_sf(data=md_counties) +
geom_sf(data=md_zips) +
theme_minimal()
foreclosure_zip <- read_csv("data/Maryland_Notices_of_Intent_to_Foreclose_by_Zip_Code.csv") |> clean_names()
foreclosure_zip_march_2023 <- foreclosure_zip |>
select(zip, march_2023)
View(foreclosure_zip_march_2023)
zip_codes_with_foreclosures <- md_zips |> left_join(foreclosure_zip_march_2023, join_by(ZIPCODE1==zip))
county_centroids <- st_centroid(zip_codes_with_foreclosures)
ggplot() +
geom_sf(data=zip_codes_with_foreclosures, aes(fill=march_2023)) +
scale_colour_viridis_b(option="magma") + #makes the scale bar to the right
theme_minimal()
library(tidyverse)
library(sf)
library(janitor)
library(tidycensus)
#census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")
md_county_notices <- read_csv("data/Maryland_Foreclosure_Data_by_County.csv") |> slice(1) |> pivot_longer(cols=-c('Date', 'Type'), names_to='county', values_to = 'notices')
md_county_population <- get_acs(geography = "county",
variables = c(population = "B01001_001"),
year = 2021,
state = "MD")
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics("images/geolayers.jpg")
library(tidyverse)
library(sf)
library(janitor)
# library(maptools)
md_zips <- st_read("data/md_zips/BNDY_ZIPCodes11Digit_MDP.shp")
glimpse(md_zips)
View(md_zips)
md_zips |>
ggplot() +
geom_sf() +
theme_minimal()
# install.packages('tigris')
library(tigris)
counties <- counties()
glimpse(counties)
md_counties <- counties |>
filter(STATEFP == "24")
md_counties |>
ggplot() +
geom_sf() +
theme_minimal()
ggplot() +
geom_sf(data=md_counties) +
geom_sf(data=md_zips) +
theme_minimal()
foreclosure_zip <- read_csv("data/Maryland_Notices_of_Intent_to_Foreclose_by_Zip_Code.csv") |> clean_names()
foreclosure_zip_march_2023 <- foreclosure_zip |>
select(zip, march_2023)
View(foreclosure_zip_march_2023)
zip_codes_with_foreclosures <- md_zips |> left_join(foreclosure_zip_march_2023, join_by(ZIPCODE1==zip))
county_centroids <- st_centroid(zip_codes_with_foreclosures)
ggplot() +
geom_sf(data=zip_codes_with_foreclosures, aes(fill=march_2023)) +
scale_colour_viridis_b(option="magma") + #makes the scale bar to the right
theme_minimal()
library(tidyverse)
library(sf)
library(janitor)
library(tidycensus)
#census_api_key("549950d36c22ff16455fe196bbbd01d63cfbe6cf")
md_county_notices <- read_csv("data/Maryland_Foreclosure_Data_by_County.csv") |> slice(1) |> pivot_longer(cols=-c('Date', 'Type'), names_to='county', values_to = 'notices')
md_county_population <- get_acs(geography = "county",
variables = c(population = "B01001_001"),
year = 2021,
state = "MD")
setwd("~/Google Drive/My Drive/JOUR472/data_journalism_2023_fall/white_house_visitor_logs")
library(tidyverse)
library(janitor)
library(lubridate)
## set working directory
## setwd("~/Google Drive/My Drive/JOUR472/data_journalism_2023_fall/white_house_visitor_logs")
wh_visitor_data <- read_csv("data/combined.csv")
wh_visitor_data <- wh_visitor_data |>
mutate(as_datetime(mdy_hm(APPT_MADE_DATE))) |>  ## when I run this, R works but tells me that "14 failed to parse." I cannot for the life of me figure out what it's unhappy about
mutate(as_datetime(mdy_hm(TOA))) |>
mutate(as_datetime(mdy_hm(TOD))) |>
mutate(as_datetime(mdy_hm(APPT_START_DATE))) |>
mutate(as_datetime(mdy_hm(APPT_END_DATE))) |>
mutate(as_datetime(mdy_hm(APPT_CANCEL_DATE))) |>
mutate(as_datetime(mdy_hm(LASTENTRYDATE))) |>
mutate(as_datetime(mdy(RELEASEDATE))) |>
## I'm sure there's a way to get it to not put it in a new column but I can't figure out how - I know mutate means it will convert into a new column but...it doesn't work without the "mutate." I dunno.
clean_names()
wh_visitor_data <- wh_visitor_data |>
mutate(as_datetime(mdy_hm(APPT_MADE_DATE))) |>  ## when I run this, R works but tells me that "14 failed to parse." I cannot for the life of me figure out what it's unhappy about
mutate(as_datetime(mdy(TOA))) |>
mutate(as_datetime(mdy(TOD))) |>
mutate(as_datetime(mdy(APPT_START_DATE))) |>
mutate(as_datetime(mdy(APPT_END_DATE))) |>
mutate(as_datetime(mdy(APPT_CANCEL_DATE))) |>
mutate(as_datetime(mdy(LASTENTRYDATE)))
wh_visitor_data
group_by(date_of_visit) |>
summarize(count=n())
wh_visitor_data |>
group_by(date_of_visit) |>
summarize(count=n())
View(wh_visitor_data)
wh_visitor_data <- read_csv("data/combined.csv")
wh_visitor_data <- wh_visitor_data |>
mutate(as_datetime(mdy_hm(APPT_END_DATE)))
wh_visitor_data |>
filter(APPT_END_DATE == mdy("07-02-2023"))
wh_visitor_data |>
filter(str_detect(APPT_END_DATE, "07-02-2023"))
wh_visitor_data |>
mutate(date = as_date(APPT_END_DATE))
wh_visitor_data <- wh_visitor_data |>
mutate(as_datetime(mdy_hm(APPT_END_DATE)))
wh_visitor_data |>
mutate(date = as_date(APPT_END_DATE))
wh_visitor_data |>
mutate(date = as_date(as_datetime(mdy_hm(APPT_END_DATE))))
wh_visitor_data |>
mutate(date = as_date(as_datetime(mdy_hm(APPT_END_DATE)))) |>
filter(str_detect(date, "07-02-2023"))
group_by(date) |>
summarize(count=n())
wh_visitor_data |>
mutate(date = as_date(as_datetime(mdy_hm(APPT_END_DATE)))) |>
filter(str_detect(date, "07-02-2023")) |>
group_by(date) |>
summarize(count=n())
wh_visitor_data |>
mutate(date = as_date(as_datetime(mdy_hm(APPT_END_DATE)))) |>
filter(str_detect(date, "07-02-2023"))
wh_visitor_data |>
mutate(date = as_date(as_datetime(mdy_hm(APPT_END_DATE))))
wh_visitor_data |>
mutate(date = as_date(as_datetime(mdy_hm(APPT_END_DATE)))) |>
filter(str_detect(date, "2023-07-02")) |>
group_by(date) |>
summarize(count=n())
###mutate(toa_time = ymd_hms(toa) |> time()) we need to figure out how to separate out time from these two columns as well
clean_wh_visitor_data |>
group_by(toa_date) |>
summarize(count=n()) |>
arrange(desc(count))
library(tidyverse)
library(janitor)
library(lubridate)
###asked chatgpt how to turn a character column into a date time column, gave it some examples from our code and int told me to do this:
wh_visitor_data <- read_csv("data/combined.csv") |> clean_names() |>
mutate(toa = mdy_hm(toa)) |>
mutate(tod = mdy_hm(tod)) |>
mutate(appt_made_date = mdy_hm(appt_made_date))  |>
mutate(appt_start_date = mdy(appt_start_date))  |>
mutate(appt_end_date = mdy_hm(appt_end_date))  |>
mutate(lastentrydate = mdy_hm(lastentrydate))  |>
mutate(releasedate = mdy(releasedate))
glimpse(wh_visitor_data)
# We want a clean single dataframe to work with. Right now there are a lot of columns that might not be particularly interesting or useful. For example, let's get rid of x28 and x29, caller room, appt cancel date, terminal suffix, poa, tod, pod,  meeting room, and post.
clean_wh_visitor_data <- wh_visitor_data |>
select(-poa, -access_type, -pod, -appt_cancel_date, -caller_room, -x28, -x29, -uin, -bdgnbr, -last_updatedby, -post, -terminal_suffix,-caller_name_last, -caller_name_first)
###note - we were having problems with this so I asked chatgpt: how do I make a new column with just the date from a column that includes date and time using lubridate and the tidyverse? it told me to do mutate(toa_date = ymd_hms(toa) %>% date())
clean_wh_visitor_data <- clean_wh_visitor_data |>
mutate(toa_date = ymd_hms(toa) |> date()) |>
mutate(tod_date = ymd_hms(tod) |>date())
